{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1500 \n",
    "\n",
    "def change_k(n_clusters, dataset, algorithm):\n",
    "    if dataset is 'blobs':\n",
    "        X, y = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "    elif dataset is 'circles':\n",
    "        X, Y = datasets.make_circles(n_samples=n_samples, factor=.5, noise=.05)\n",
    "    elif dataset is 'moons':\n",
    "        X, Y = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "    elif dataset is 'no_structure':\n",
    "        X, Y = np.random.rand(n_samples, 2), None \n",
    "    elif dataset is 'anisotropic':\n",
    "        X, Y = datasets.make_blobs(n_samples=n_samples, random_state=170)\n",
    "        transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "        X = np.dot(X, transformation)\n",
    "    elif dataset == 'varied variance':\n",
    "        X, Y = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=170)\n",
    "    elif dataset == 'iris':\n",
    "        X, y = datasets.load_iris().data, datasets.load_iris().target\n",
    "    elif dataset == 'MNIST PCA Reduced':\n",
    "        X, y = datasets.load_digits().data, datasets.load_digits().target\n",
    "        X = PCA(n_components=2).fit_transform(X)\n",
    "        \n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    if algorithm == 'kmeans++':\n",
    "        algorithm = cluster.KMeans(n_clusters=n_clusters, init='k-means++')\n",
    "    elif algorithm == 'kmeans':\n",
    "        algorithm = cluster.KMeans(n_clusters=n_clusters, init='random')\n",
    "    elif algorithm == 'GMM full':\n",
    "        # 'full' (each component has its own general covariance matrix)\n",
    "        algorithm = mixture.GaussianMixture(n_components=n_clusters, covariance_type='full')\n",
    "    elif algorithm == 'GMM tied':\n",
    "        # 'tied' (all components share the same general covariance matrix),\n",
    "        algorithm = mixture.GaussianMixture(n_components=n_clusters, covariance_type='tied')\n",
    "    elif algorithm == 'GMM spherical':\n",
    "        # 'spherical' (each component has its own single variance).\n",
    "        algorithm = mixture.GaussianMixture(n_components=n_clusters, covariance_type='spherical')\n",
    "    elif algorithm == 'GMM diag':\n",
    "        # 'diag' (each component has its own diagonal covariance matrix),\n",
    "        algorithm = mixture.GaussianMixture(n_components=n_clusters, covariance_type='diag')\n",
    "    elif algorithm == 'kmeans RBF kernel':\n",
    "        algorithm = cluster.SpectralClustering(n_clusters=n_clusters, affinity=\"rbf\")\n",
    "    elif algorithm == 'kmeans nearest neighbor kernel': \n",
    "        algorithm = cluster.SpectralClustering(n_clusters=n_clusters, affinity=\"nearest_neighbors\")\n",
    "            \n",
    "    algorithm.fit(X)\n",
    "    \n",
    "    if hasattr(algorithm, 'labels_'):\n",
    "        y_pred = algorithm.labels_.astype(np.int) \n",
    "    else:\n",
    "        y_pred = algorithm.predict(X)\n",
    "\n",
    "    colors = np.array(['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                       '#f781bf', '#a65628', '#984ea3',\n",
    "                       '#999999', '#e41a1c', '#dede00', \n",
    "                       '#000000'][0:max(y_pred)+1])\n",
    "    \n",
    "    ax = plt.subplot(111)\n",
    "    plt.scatter(X[:, 0], X[:, 1], color=colors[y_pred])\n",
    "    \n",
    "    if hasattr(algorithm, 'covariances_'):\n",
    "        for n, color in enumerate(colors):\n",
    "            if algorithm.covariance_type == 'full':\n",
    "                covariances = algorithm.covariances_[n][:2, :2]\n",
    "            elif algorithm.covariance_type == 'tied':\n",
    "                covariances = algorithm.covariances_[:2, :2]\n",
    "            elif algorithm.covariance_type == 'diag':\n",
    "                covariances = np.diag(algorithm.covariances_[n][:2])\n",
    "            elif algorithm.covariance_type == 'spherical':\n",
    "                covariances = np.eye(algorithm.means_.shape[1]) * algorithm.covariances_[n]\n",
    "            v, w = np.linalg.eigh(covariances)\n",
    "            u = w[0] / np.linalg.norm(w[0])\n",
    "            angle = np.arctan2(u[1], u[0])\n",
    "            angle = 180 * angle / np.pi  # convert to degrees\n",
    "            v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "            ell = mpl.patches.Ellipse(algorithm.means_[n, :2], v[0], v[1],\n",
    "                                      180 + angle, color=color)\n",
    "            ell.set_clip_box(ax.bbox)\n",
    "            ell.set_alpha(0.5)\n",
    "            ax.add_artist(ell)\n",
    "\n",
    "interact(change_k, \n",
    "        n_clusters=ipywidgets.IntSlider(value=1, min=1, max=10, step=1),\n",
    "        dataset=['blobs', 'circles', 'moons', 'no_structure', 'anisotropic', 'varied variance', 'iris', 'MNIST PCA Reduced'],\n",
    "        algorithm= ['kmeans++', 'kmeans', 'GMM full', 'GMM tied', 'GMM spherical', 'GMM diag', \n",
    "                    'kmeans RBF kernel', 'kmeans nearest neighbor kernel']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction: PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn import datasets\n",
    "\n",
    "def demo_pca(dataset):\n",
    "    np.random.seed(0)\n",
    "    n_samples=400\n",
    "    if dataset is 'blobs':\n",
    "        X, y = datasets.make_blobs(n_samples=n_samples, random_state=4)\n",
    "    elif dataset is 'circles':\n",
    "        X, Y = datasets.make_circles(n_samples=n_samples, factor=.5, noise=.05)\n",
    "    elif dataset is 'moons':\n",
    "        X, Y = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "    elif dataset is 'no_structure':\n",
    "        X, Y = np.random.rand(n_samples, 2), None \n",
    "    elif dataset is 'anisotropic':\n",
    "        X, Y = datasets.make_blobs(n_samples=n_samples, random_state=170)\n",
    "        transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "        X = np.dot(X, transformation)\n",
    "    elif dataset == 'varied variance':\n",
    "        X, Y = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=170)\n",
    "    elif dataset == 'iris':\n",
    "        X, y = datasets.load_iris().data, datasets.load_iris().target\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    pca = KernelPCA(n_components=1, \n",
    "                    kernel=\"linear\", \n",
    "                    fit_inverse_transform=True)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_back = pca.inverse_transform(X_pca)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(X[:, 0], X[:, 1], 'bo', label='Original Data');\n",
    "    plt.plot(X_back[:, 0], X_back[:, 1], 'r*', label='PCA reduced Data');\n",
    "    plt.legend()\n",
    "\n",
    "    # print(\"Total explained variance: {}\".format(pca.explained_variance_ratio_[0]))\n",
    "\n",
    "interact(demo_pca, \n",
    "         dataset=['blobs', 'circles', 'moons', 'no_structure', 'anisotropic', 'varied variance', 'iris'],\n",
    "         # kernel=['linear', 'poly', 'rbf'],\n",
    "         # n_components=ipywidgets.IntSlider(value=1, min=1, max=2, step=1),\n",
    "         # gamma = ipywidgets.FloatSlider(value=0, min=-3, max=3, step=0.5)\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn import datasets\n",
    "\n",
    "n_samples=400\n",
    "np.random.seed(0)\n",
    "dataset = 'circles'\n",
    "if dataset is 'blobs':\n",
    "    X, y = datasets.make_blobs(n_samples=n_samples, random_state=4)\n",
    "elif dataset is 'circles':\n",
    "    X, y = datasets.make_circles(n_samples=n_samples, factor=.3, noise=.05)\n",
    "elif dataset is 'moons':\n",
    "    X, y = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "\n",
    "reds = y==0\n",
    "blues = y==1 \n",
    "\n",
    "\n",
    "# X = X - np.mean(X, axis=0) \n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca = KernelPCA(n_components=2, kernel=\"rbf\", fit_inverse_transform=True, gamma=10)\n",
    "reds = y==0\n",
    "blues = y==1 \n",
    "X_pca = pca.fit_transform(X)\n",
    "X_back = pca.inverse_transform(X_pca)\n",
    "\n",
    "# plt.scatter(X[:, 0], X[:, 1], color='b', label='Original data')\n",
    "plt.figure()\n",
    "plt.title(\"Original Data\")\n",
    "plt.scatter(X[reds, 0], X[reds, 1], color='r');\n",
    "plt.scatter(X[blues, 0], X[blues, 1], color='b');\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"PCA space of Data\")\n",
    "plt.scatter(X_pca[reds, 0], X_pca[reds, 1], color='r');\n",
    "plt.scatter(X_pca[blues, 0], X_pca[blues, 1], color='b');\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(X_back[reds, 0], X_back[reds, 1], color='r');\n",
    "# plt.scatter(X_back[blues, 0], X_back[blues, 1], color='b');\n",
    "# # \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction: PCA  vs LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit(X).transform(X)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit(X, y).transform(X)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "colors = ['r', 'g', 'b']\n",
    "\n",
    "for i, target_name in enumerate(target_names):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=colors[i], alpha=.8,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of IRIS dataset')\n",
    "\n",
    "plt.figure()\n",
    "for i, target_name in enumerate(target_names):\n",
    "    plt.scatter(X_lda[y == i, 0], X_lda[y == i, 1], color=colors[i], alpha=.8,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of IRIS dataset'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "epochs = 40 \n",
    "batch_size = 256 \n",
    "# reg_param = 1e-4\n",
    "\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=epochs ,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                verbose=1)\n",
    "\n",
    "\n",
    "# # this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# # create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# # retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# # create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input), name='decoder')\n",
    "\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display code\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(encoded_imgs[i].reshape(-1, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "np.random.shuffle(x_train_noisy)\n",
    "np.random.shuffle(x_test_noisy)\n",
    "\n",
    "autoencoder.fit(x_train_noisy, x_train_noisy,\n",
    "                epochs=epochs ,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test_noisy),\n",
    "                verbose=1)\n",
    "\n",
    "encoded_imgs = encoder.predict(x_test_noisy)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display code\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(encoded_imgs[i].reshape(-1, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
