{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "Libraries being used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import CompoundKernel, ConstantKernel, DotProduct, ExpSineSquared, Exponentiation, Hyperparameter, Kernel, Matern, PairwiseKernel, Product, RationalQuadratic, RBF, Sum, WhiteKernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method `data_loading()`\n",
    "First, we load the data from the csv file and put into a pandas dataframe. After that the data is preprocessed by replacing the categorical values in the `season`column with humerical values. After that we are using the K-Nearest Neighbor (KNN) imuter so that we can fill in the missing values. This is done by first fiting the imputer on the training data and then later transforms both the training and the test data using the `transform`method. At last we are splitting the data into the features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing \n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    # # Dummy initialization of the X_train, X_test and y_train   \n",
    "    # X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "    # y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    # X_test = np.zeros_like(test_df)\n",
    "\n",
    "    #Performing data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "\n",
    "    X_train = train_df.drop(['price_CHF'], axis=1)\n",
    "    X_train = X_train.replace({'spring':'0', \"summer\":\"1\", \"autumn\":\"2\", \"winter\":\"3\"})\n",
    "\n",
    "    X_test = test_df.replace({'spring':'0', \"summer\":\"1\", \"autumn\":\"2\", \"winter\":\"3\"})\n",
    "    train_df_replaced = train_df.replace({'spring':'0', \"summer\":\"1\", \"autumn\":\"2\", \"winter\":\"3\"})\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=2)\n",
    "    imputer.fit(X_train)\n",
    "    X_train = imputer.transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "\n",
    "    imputer2 = KNNImputer(n_neighbors=2)\n",
    "    imputer2.fit(train_df_replaced)\n",
    "    y_train = imputer2.transform(train_df_replaced)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_train = y_train[:, 2]\n",
    "\n",
    "    assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method `modeling_and_prediction`\n",
    "This method is taking 3 arguments which are `X_train`, `y_traing`and `X_test`. Initially I tried using linear regression, but that gave me a very low accuracy score. Instead as sugested in the assignment I used the Guassian Naive Bayes Model to fit the training data and then to make the prediciton on the test data. I tried multiple different kernal, but the best one which I got was the RationalQuadratic which my partener figured out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_and_prediction(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    This function defines the model, fits training data and then does the prediction with the test data \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with 10 features\n",
    "    y_train: array of floats, training output\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    y_test: array of floats: dim = (100,), predictions on test set\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred=np.zeros(X_test.shape[0])\n",
    "\n",
    "    ## Defining the model and fit it using training data. Then, use test data to make predictions\n",
    "\n",
    "    ## Trying out different kernels\n",
    "    # model = GaussianProcessRegressor(kernel=ConstantKernel())\n",
    "    # model = GaussianProcessRegressor(kernel=DotProduct())\n",
    "    # model = GaussianProcessRegressor(kernel=ExpSineSquared())\n",
    "    # model = GaussianProcessRegressor(kernel=Exponentiation())\n",
    "    # model = GaussianProcessRegressor(kernel=Hyperparameter())\n",
    "    # model = GaussianProcessRegressor(kernel=Kernel())\n",
    "    # model = GaussianProcessRegressor(kernel=Matern())\n",
    "    # model = GaussianProcessRegressor(kernel=PairwiseKernel())\n",
    "    # model = GaussianProcessRegressor(kernel=Product())\n",
    "    model = GaussianProcessRegressor(kernel=RationalQuadratic()) # Best kernel\n",
    "    # model = GaussianProcessRegressor(kernel=RBF())\n",
    "    # model = GaussianProcessRegressor(kernel=Sum())\n",
    "    # model = GaussianProcessRegressor(kernel=WhiteKernel())\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    assert y_pred.shape == (100,), \"Invalid data shape\"\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results file successfully generated!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Data loading\n",
    "    X_train, y_train, X_test = data_loading()\n",
    "    # The function retrieving optimal LR parameters\n",
    "    y_pred=modeling_and_prediction(X_train, y_train, X_test)\n",
    "    # Save results in the required format\n",
    "    dt = pd.DataFrame(y_pred) \n",
    "    dt.columns = ['price_CHF']\n",
    "    dt.to_csv('results.csv', index=False)\n",
    "    print(\"\\nResults file successfully generated!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
